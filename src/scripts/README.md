## üõ†Ô∏è Evaluation Method

**RoTBench Evaluation**  
RoTBench adapts three metrics, **Tool Selection (TS)**, **Parameter identification (PI)** and **Content filling (CF)**, to evalute funciton calling. Related methods are described in RoTBench_eval.py. To evaluate RoTBench, input should follow format:

**Tool Selection (TS)** represents whether agent can choose right function.
**Parameter identification (PI)** represents whether agent can fill right parameter name into function.
**Content filling (CF)** denotes whether agent can fill corrent content into corresponding parameters.

Input format include two files, **test_file** and **prediction_file**, which test_file should follow share_gpt file(.json) and prediction file should follow generated_predictions file format(.jsonl).

Run RoTBench Evaluation:
```
python src/scripts/RoTBench_eval.py --test_file PATH --answer_file PATH
```
 
 **Teval Evaluation**  
 ```
python teval_eval.py
 ```

 **ToolAlpaca Evaluation**   
 `$EVAL_FILE` is the path to the evaluation file, expected to be a .jsonl file generated by LLAMA-Factory.  
 `$DATA_FILE` is the path to the data file, default to be the real api evaluation file obtained by `data/toolalpaca.sh`.
```
sh toolalpaca_eval.sh $EVAL_FILE $DATA_FILE
```
